{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code creates 2 files:\n",
        "\n",
        "1. full_c_analogies : This text file contains analogies having words in the brown corpus.\n",
        "2. top_c_analogies : This text file contains analogies having words in the top 5028 words in the brown corpus."
      ],
      "metadata": {
        "id": "5MZzuRRiEdUG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3lGd5GfD4qX"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "nltk.download(\"brown\")\n",
        "nltk.download(\"stopwords\")\n",
        "from string import punctuation\n",
        "from nltk.corpus import brown\n",
        "from nltk import bigrams\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting High frequency words\n",
        "freq_of_words = Counter({})\n",
        "stop_words = set(stopwords.words('english')+list(punctuation)+[\"``\",\"''\",\"--\"])\n",
        "\n",
        "for c in brown.categories():\n",
        "  words_wo_numbers = [w for w in brown.words(categories=c) if not w.isnumeric()]\n",
        "  words_wo_stop_words = [w for w in words_wo_numbers if not w.lower() in stop_words]\n",
        "  freq_of_words += Counter(words_wo_stop_words)\n",
        "\n",
        "freq_of_words = dict(freq_of_words)\n",
        "\n",
        "all_freq_words = sorted(freq_of_words,key=freq_of_words.get,reverse=True)[:]\n",
        "highest_freq_words = all_freq_words[:5000]\n",
        "n_words = ['asylum','autograph','automobile','boy','bird','brother','cord','cushion','coast','cementary','crane','car','cock','fruit','furnace','forest','food','grin','graveyard','glass','gem','hill','implement','jewel','journey','lad','monk','midday','madhouse','mound','magician','noon','oracle','pillow','rooster','smile','string','sage','shore','serf','slave','signature','stove','tumbler','tool','voyage','wizard','woodland']\n",
        "words_in_brown_corpus = [ w for w in n_words if w in freq_of_words ]\n",
        "\n",
        "words=highest_freq_words+[w for w in words_in_brown_corpus if w not in highest_freq_words]"
      ],
      "metadata": {
        "id": "LHqUyCZzEA0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = open('all_analogies.txt', 'r')\n",
        "analogies = file1.readlines()\n",
        "full_c_analogies=[]\n",
        "top_c_analogies=[]\n",
        "\n",
        "for analogy in analogies:\n",
        "  if(analogy[0]==':'):\n",
        "    full_c_analogies.append(analogy)\n",
        "    top_c_analogies.append(analogy)\n",
        "  else:\n",
        "    ws=analogy.split()\n",
        "    w_in_hf=0\n",
        "    w_in_all=0\n",
        "    for w in ws:\n",
        "      if w in highest_freq_words:\n",
        "        w_in_hf+=1\n",
        "        w_in_all+=1\n",
        "      elif w in all_freq_words:\n",
        "        w_in_all+=1\n",
        "      else:\n",
        "        break\n",
        "    if w_in_hf==4:\n",
        "      full_c_analogies.append(analogy)\n",
        "      top_c_analogies.append(analogy)\n",
        "    elif w_in_all==4:\n",
        "      full_c_analogies.append(analogy)\n",
        "\n",
        "with open('full_c_analogies.txt', 'w') as f:\n",
        "    f.writelines(full_c_analogies)\n",
        "\n",
        "with open('top_c_analogies.txt', 'w') as f:\n",
        "    f.writelines(top_c_analogies)"
      ],
      "metadata": {
        "id": "EaT3ObufEPR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For further use, top_c_analogies.txt file was used whcih was further divided into semantic analogies and syntactic analogies based on the topics."
      ],
      "metadata": {
        "id": "iGmqf5A4GRTN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ccVFmKPGgJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}